<!doctype html>
<html>
  <head>

    <title>tensorflow 로 checkpoint 파일(.ckpt)과 ckeckpoint state proto 이용하기 : Variable 저장과 재활용 | Jayne.who();</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!--bootstrap CSS-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb" crossorigin="anonymous">
    <!--code highlighter CSS for Jekyll Markdown to HTML Converter -->
    <link rel="stylesheet" href="/asset/static/vim-highlight-rouge.css" />
    <link rel="stylesheet" href="/asset/static/post_load.css" />
    <link rel="stylesheet" href="/asset/static/font/stylesheets/NotoSansKR-Hestia.css" />
    <style>
      body {
          font-family: 'Noto Sans Korean', sans-serif;
          font-weight: 450;
          padding-top: 50px;
        }
      h1,h2,h3,h4,h5,h6 {
        font-weight : 800;
        color : #148b8e;
      }
      .navbar, .nav {
        font-weight: 800;
      }
      a {
        color : #90b3d8;
      }
    </style>
  </head>
  <body>

    

<nav id = "navbarbackground" class="navbar fixed-top navbar-expand-lg navbar-light" style="background-color : rgba(178, 85, 228, 0.94); background-image:url('/asset/media/image/gradient1.jpg');   background-blend-mode: color;
  background-size: cover;">
  <a class="navbar-brand" href="/">
    <img src="/asset/media/image/logo.jpg" width="35" height="35" class="d-inline-block align-top border border-primary" alt="" style="border-radius:10px">
    Jayne.who();
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav" style="font-weight : 600;">
      <li class="nav-item" id="navbar_profile">
        <a class="nav-link" href="/profile/">Profile </a>
      </li>
      <li class="nav-item" id="navbar_post">
        <a class="nav-link" href="/post/">Posts </a>
      </li>
      <li class="nav-item" id="navbar_project">
        <a class="nav-link" href="/project/">Projects </a>
      </li>
    </ul>
  </div>
</nav>

    <style>
/*post titles style*/
.post h1,h2,h3,h4,h5,h6 {
  color: #3f71f4;

}
.post h1 {font-size: 2.0rem;padding-top: 4.5rem;padding-bottom:1rem;}
.post h2 {font-size: 1.7rem;}
.post h3 {font-size: 1.6rem;}
.post h4 {font-size: 1.4rem;}
.post h5 {font-size: 1.2rem;}
/*for image*/
.post img {
  max-width: 100%;
  height: auto;
}

/*for code highlighter*/
pre {
  background-color: #494b4c ;
  border-radius: 6px;
  padding: 10px;
  color : #d0d7de;
}


</style>

<div class="container-fluid text-center pt-3" style="background-image : url('/asset/media/image/post/8/1.png');  background-color: #00010299; background-blend-mode: color; background-size: cover; min-height: 350px;">
  <a href="/post/"><p class="text-left md-5"><button type="button" class="btn btn-outline-secondary btn-sm d-inline text-uppercase"> < Back </button></p></a>
  <h1 class="card-title text-white" style="font-size : 2.2rem;">tensorflow 로 checkpoint 파일(.ckpt)과 ckeckpoint state proto 이용하기 : Variable 저장과 재활용</h1>
  <p class="card-text text-white"><p class="text-muted">deeplearning | 29 July 2017</p></p>
  <p class="card-text text-white">
    Tags |
    
    <a href="#" class="badge badge-primary">tensorflow</a>
    
    <a href="#" class="badge badge-primary">python</a>
    
  </p>
</div>


<div class="post container pt-5 " style = "max-width : 750px"><p>tensorflow 로 학습시킨 딥러닝 모델을 저장하는 방법중 하나로 <code class="highlighter-rouge">Checkpoint</code> 을 이용하는 방법이 있다.</p>

<p><code class="highlighter-rouge">Checkpoint</code> 은 학습된 모델의 Variable 값을 저장하는 파일이다.</p>

<p><code class="highlighter-rouge">Checkpoint</code> 파일을 저장하고 불러옴으로써 학습된 모델을 재사용하고, 지난 학습을 이어서 더 하고 하는 작업들이 가능해진다.</p>

<p>이번 글에서는 <code class="highlighter-rouge">Checkpoint</code> 파일을 다루는 tensorflow 모듈에 대해서 알아보고, 능숙하게 딥러닝 모델을 저장하고 불러오는 작업을 수행할 수 있도록 하는 것이 목표이다.</p>

<p><br />
<br /></p>
<h1 id="0-모델-디렉터리-구조">0. 모델 디렉터리 구조</h1>
<hr />

<p><br /></p>

<p>project(root)<br />
ㄴmodel<br />
~ ㄴgraph.py<br />
~ ㄴrunner.py<br />
~ ㄴutils.py<br />
ㄴdata<br />
~ ㄴtrain_data<br />
~ ㄴtest_data<br />
ㄴsaved<br />
~ <br /></p>

<p>프로젝트 디렉터리 구조가 이렇다고 가정한다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#/model/graph.py</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="p">:</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s">"v1"</span><span class="p">)</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s">"v2"</span><span class="p">)</span>
</code></pre>
</div>

<p><br />
<br /></p>
<h1 id="1-checkpoint-저장">1. checkpoint 저장</h1>
<hr />

<p><br /></p>

<p>위의 모델 그래프를 학습시키면서, 학습된 모델의 Variable 들을 checkpoint에 저장해본다.</p>

<p>첫번째 training job 의 이름을 train1 이라고 하자.</p>

<p>train1 job 의 결과물은 <code class="highlighter-rouge">/saved/train1.ckpt</code> 에 저장할 것이다.</p>

<p>그러기 위해서는 <code class="highlighter-rouge">Checkpoint</code>파일을 저장해주는 tf.train.Saver() 클래스를 이용해야한다.</p>

<p>참고 : <a href="https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops/saving_and_restoring_variables">tensorflow api 공식 doc : tf.train.Saver</a></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#/model/train.py</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>

    <span class="c"># Saver instance 를 생성한다.</span>
    <span class="c"># Saver.save(sess, ckpt_path)</span>
    <span class="c"># Saver.restore(sess, ckpt_path)</span>

    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="c"># 그래프를 돌리다가 Variable 을 저장하고 싶을 때 Saver.save() 메서드를 사용한다.</span>
    <span class="c"># args : tf.Session, job`s checkpoint file path</span>
    <span class="c"># return : job`s checkpoint file path (String)</span>

    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s">"saved/train1"</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"job`s ckpt files is save as : "</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>job`s ckpt files is save as :  saved/train1
</code></pre>
</div>

<p>위의 코드를 수행하고 나면 프로젝트의 /saved 디렉터리에 새로운 파일들이 생성된다.</p>

<p>project(root)<br />
ㄴmodel<br />
~ ㄴgraph.py<br />
~ ㄴrunner.py<br />
~ ㄴutils.py<br />
ㄴdata<br />
~ ㄴtrain_data<br />
~ ㄴtest_data<br />
ㄴsaved<br />
~ ㄴ<strong>checkpoint</strong><br />
~ ㄴ<strong>train1.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train1.ckpt.index</strong><br />
~ ㄴ<strong>train1.ckpt.meta</strong><br /></p>

<p>이들중 job name 인 train1 으로 시작하는 세개의 파일이 train1 job 의 Checkpoint 파일이다.</p>

<p>맨 위의 checkpoint 란 이름의 파일은 조금 이따 이야기한다.
<br />
<br /><br />
<br /></p>

<p>첫번째 training job : train1 의 결과가 만족스럽지 못해서, 모델을 조금 수정해서 다시 training 을 하려고 한다.</p>

<p>이번 job 의 이름은 train2 라고 하자.</p>

<p>train2 job 의 결과물을 /saved/train2.ckpt 에 저장하는데, 이번엔 매 iteration마다 Variables 의 값을 저장하고싶다.</p>

<p>이럴땐 job의 이름을 유지한채로, iteration 별로 <code class="highlighter-rouge">Checkpoint file</code>을 별도로 생성할 수 있다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#/model/train.py(수정함)</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>

    <span class="c"># 위와 마찬가지로 Saver 생성</span>

    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>

        <span class="c"># 매 step 마다 모델 저장하고 싶다면 save 메서드에 step 인자를 하나 추가한다.</span>
        <span class="c"># args : tf.Session, job`s checkpoint file path, step</span>
        <span class="c"># return : job`s checkpoint file path (String)</span>

        <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s">"saved/train2"</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"save ckpt file:"</span> <span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>save ckpt file: saved/train2-0
save ckpt file: saved/train2-1
save ckpt file: saved/train2-2
save ckpt file: saved/train2-3
save ckpt file: saved/train2-4
save ckpt file: saved/train2-5
save ckpt file: saved/train2-6
save ckpt file: saved/train2-7
save ckpt file: saved/train2-8
save ckpt file: saved/train2-9
</code></pre>
</div>

<p>보다시피 train1 job 과는 다르게 job name 뒤에 iteration의 step 이 적혀져서 총 10묶음의 체크포인트가 만들어진다.</p>

<p>project(root)<br />
ㄴmodel<br />
~ ㄴgraph.py<br />
~ ㄴrunner.py<br />
~ ㄴutils.py<br />
ㄴdata<br />
~ ㄴtrain_data<br />
~ ㄴtest_data<br />
ㄴsaved<br />
~ ㄴ<strong>checkpoint</strong><br />
~ ㄴtrain1.ckpt.data-00000-of-00001<br />
~ ㄴtrain1.ckpt.index<br />
~ ㄴtrain1.ckpt.meta<br />
~ ㄴ<strong>train2-0.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train2-0.ckpt.index</strong><br />
~ ㄴ<strong>train2-0.ckpt.meta</strong><br />
~ ㄴ<strong>train2-1.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train2-1.ckpt.index</strong><br />
~ ㄴ<strong>train2-1.ckpt.meta</strong><br />
~ ㄴ<strong>train2-2.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train2-2.ckpt.index</strong><br />
~ ㄴ<strong>train2-2.ckpt.meta</strong><br /></p>

<p>.
.
.</p>

<p>~ ㄴ<strong>train2-8.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train2-8.ckpt.index</strong><br />
~ ㄴ<strong>train2-8.ckpt.meta</strong><br />
~ ㄴ<strong>train2-9.ckpt.data-00000-of-00001</strong><br />
~ ㄴ<strong>train2-9.ckpt.index</strong><br />
~ ㄴ<strong>train2-9.ckpt.meta</strong><br /></p>

<p><br />
<br /></p>
<h1 id="2-checkpoint-state-proto">2. checkpoint state proto</h1>
<hr />

<p><br /></p>

<p><img src="/images/tf_ckpt_use/ckptstateproto.png" alt="" /></p>

<p>위의 사진은 <a href="https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops/saving_and_restoring_variables">tensorflow api 공식 doc : tf.train.Saver</a> 사이트에서 볼 수 있는 <strong><em>Checkpoint State Protocol Buffer</em></strong> 에 대한 정보이다.</p>

<p>이름도 거대한 <strong><em>Checkpoint State Protocol Buffer</em></strong> 에 대해서 알 필요가 있다.</p>

<p>Saver 의 save 모듈을 이용해 모델을 저장할 때, Saver 는 <strong><em>Checkpoint State Protocol Buffer</em></strong> 를 /saved/checkpoint 파일에 담아 저장하고, 새로운 job으로 학습할 때 마다 업데이트해 저장한다.</p>

<p><strong><em>Checkpoint State Protocol Buffer</em></strong> 에는 두가지 정보가 담겨있다.</p>

<ol>
  <li>model_checkpoint_path : 가장 최근에 저장된 job.ckpt 파일의 path 정보</li>
  <li>all_model_checkpoint_paths : 최근에 저장된 job_i.ckpt 파일들의 path 정보 list</li>
</ol>

<p>보통 saved 폴더에서 가장 최신의 체크포인트파일을 불러와 모델을 재학습시키거나 테스트해보려고 할때 사용한다.</p>

<p>all_model_checkpoint_paths 의 가장 마지막 원소는 model_checkpoint_path 와 동일하다.</p>

<h3 id="checkpoint-state-protocol-buffer-이용법"><strong><em>Checkpoint State Protocol Buffer</em></strong> 이용법</h3>

<p>대표적으로 두가지 방법이 있다.</p>

<ol>
  <li>tf.train.get_checkpoint_state(saved_dir_path)</li>
  <li>tf.train.latest_checkpoint(saved_dir_path)</li>
</ol>

<h4 id="1-tftrainget_checkpoint_statesaved_dir_path">1. tf.train.get_checkpoint_state(saved_dir_path)</h4>

<p><code class="highlighter-rouge">saved_dir_path</code> 에서 checkpoint 파일 안의 <strong><em>Checkpoint State Protocol Buffer</em></strong> 를 읽어온다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">ckpt_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_checkpoint_state</span><span class="p">(</span><span class="s">"saved"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ckpt_state</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"첫번째 정보 사용법:"</span><span class="p">,</span> <span class="n">ckpt_state</span><span class="o">.</span><span class="n">model_checkpoint_path</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"두번째 정보 사용법:"</span><span class="p">,</span> <span class="n">ckpt_state</span><span class="o">.</span><span class="n">all_model_checkpoint_paths</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;class 'tensorflow.python.training.checkpoint_state_pb2.CheckpointState'&gt;
첫번째 정보 사용법: saved/train2-9
두번째 정보 사용법: ['saved/train2-5', 'saved/train2-6', 'saved/train2-7', 'saved/train2-8', 'saved/train2-9']
</code></pre>
</div>

<h4 id="2-tftrainlatest_checkpointsaved_dir_path">2. tf.train.latest_checkpoint(saved_dir_path)</h4>

<p><code class="highlighter-rouge">saved_dir_path</code> 에서 checkpoint 파일 안의 <strong><em>Checkpoint State Protocol Buffer</em></strong> 에서  model_checkpoint_path 정보만 string 으로 반환한다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">recent_ckpt_job_path</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s">"saved"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">recent_ckpt_job_path</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>saved/train2-9
</code></pre>
</div>

<p><br />
<br /></p>
<h1 id="3-checkpoint-불러오기">3. checkpoint 불러오기</h1>
<hr />

<p><br /></p>

<p>저장한 체크포인트 파일들에서 Variable 들을 다시 꺼내서 재사용하려면 tf.Saver 클래스의 restore 메서들을 이용한다.</p>

<p>이때 위에서 언급한 <strong><em>Checkpoint State Protocol Buffer</em></strong> 가 매우 요긴하게 쓰인다.</p>

<p>test1 job 을 수행하는데에 train2 job 에서 마지막에 저장한 변수 ckpt 결과물을 로드해 사용하고싶다.</p>

<p>그렇다면 아래의 코드처럼 하면된다.</p>

<h3 id="case-1-직접-불러올-jobckpt-명시해주는-경우">case 1: 직접 불러올 job.ckpt 명시해주는 경우</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#/model/test.py</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>

    <span class="c"># Saver instance 를 생성한다.</span>
    <span class="c"># Saver.restore(sess, ckpt_path)</span>

    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="c"># Saver.restore()</span>
    <span class="c"># args : tf.Session, job`s checkpoint file path</span>
    <span class="c"># return : None</span>

    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s">"saved/train2-9"</span><span class="p">)</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>INFO:tensorflow:Restoring parameters from saved/train2-9
</code></pre>
</div>

<h3 id="case-2-tftrainlatest_checkpointdir_path-이용하는-경우">case 2: tf.train.latest_checkpoint(dir_path) 이용하는 경우</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c">#/model/test.py</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>

    <span class="c"># Saver instance 를 생성한다.</span>
    <span class="c"># Saver.restore(sess, ckpt_path)</span>

    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="c"># Saver.restore()</span>
    <span class="c"># args : tf.Session, job`s checkpoint file path</span>
    <span class="c"># return : None</span>

    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s">"saved"</span><span class="p">))</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>INFO:tensorflow:Restoring parameters from saved/train2-9
</code></pre>
</div>
</div>

    <div class ="container mt-5 mb-5">
  <hr  />
  <div class="row">
    <div class="col-5"> </div>
    <div class="col-2"><img src="/asset/media/image/logo.jpg" width="50" height="50" class="border border-primary px-auto" alt="" style="border-radius:10px; align-center"> </div>
    <div class="col-5"> </div>
  </div>
</div>


    <!--bootstrap Javascript-->
     <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh" crossorigin="anonymous"></script>
     <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ" crossorigin="anonymous"></script>
     <script src="/asset/static/post_load.js"></script>
     <script src="/asset/static/post_table_generation.js"></script>
     <script>
  $(document).ready(function() {
    var main_route = (window.location.pathname.split("/")[1]);
    $('#navbar_' + main_route).addClass('active');
    navbar = $('#navbarbackground');
    if (main_route == "post"){
      navbar.attr('style',"background-color:rgb(146, 146, 146); background-image:url('/asset/media/image/gradient4.png');   background-blend-mode: color; background-size: cover;");
    }
    else if(main_route == "project"){
      navbar.attr('style',"background-color:rgba(157, 157, 157, 0.54); background-image:url('/asset/media/image/gradient3.jpg');background-blend-mode:color; background-size:cover;");
    }
    else if(main_route == "profile"){
      navbar.attr('style',"background-color:rgba(190, 190, 190, 0.75); background-image:url('/asset/media/image/gradient2-1.jpg'); background-blend-mode: color; background-size: cover;");
    }
    else{
      navbar.attr('style',"background-color : rgba(178, 85, 228, 0.94); background-image:url('/asset/media/image/gradient1.jpg');   background-blend-mode: color; background-size: cover;");
    }
  });
</script>

     <script>
  $(document).ready(function() {
    var main_route = (window.location.pathname.split("/")[2]);
    $('#categorybar_' + main_route).addClass('active').addClass('bg-dark');
  });
</script>

  </body>
</html>
